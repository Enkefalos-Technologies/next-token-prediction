# Exploring Next Token Prediction in Theory of Mind (ToM) Task: A Comparative Experiment with GPT-2 and LLaMA-2 Models

## 🧠 Project Overview

This project explores the **Theory of Mind (ToM)** through NLP models by predicting next tokens and analyzing how different models—**GPT-2** and **LLaMA-2**—perform on **first-order**, **zero-order**, and **second-order** questions.

---

## 📁 Project Structure

### 🔹 Data
- `Original_stories.csv` → Contains 10 original stories from the *Explore Theory of Mind* paper.
- `infilled_stories.csv` → Infills generated using `infill_generator_using_gpt4.py`.

### 🔹 Code
- `python infill_generator_using_gpt4.py` → Run the script to generate infilled stories.
- `python gpt2_model_pred.py` → Run this script to predicts next tokens using GPT-2 and plots graphs.
- `python llama2_model_pred.py` → Run this script to predicts next tokens using LLaMA-2 and plots graphs.

## 📊Results
 
### GPT-2 Model Predictions:
 
- `gpt2_first_order_result.pdf` → First-order question results generated by gpt2.
 
- `gpt2_second_order_result.pdf` → Second-order question results generated by gpt2.
 
- `gpt2_zero_order_result.pdf` → Zero-order question results generated by gpt2.
 
### LLaMA-2 Model Predictions:
 
- `llama2_first_order_result.pdf` → First-order question results generated by llama2.
 
- `llama2_second_order_result.pdf` → Second-order question results generated by llama2.
 
- `llama2_zero_order_result.pdf` → Zero-order question results generated by llama2.
 

---

## 🧰 Requirements

- `requirements.txt` → Contains all the necessary dependencies.

Install dependencies using:

```bash
!pip install -r requirements.txt
