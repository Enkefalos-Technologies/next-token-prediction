# Exploring Next Token Prediction in Theory of Mind (ToM) Task: A Comparative Experiment with GPT-2 and LLaMA-2 Models

## ğŸ§  Project Overview

This project explores the **Theory of Mind (ToM)** through NLP models by predicting next tokens and analyzing how different modelsâ€”**GPT-2** and **LLaMA-2**â€”perform on **first-order**, **zero-order**, and **second-order** questions.

---

## ğŸ“ Project Structure

### ğŸ”¹ Data
- `Original_stories.csv` â†’ Contains 10 original stories from the *Explore Theory of Mind* paper.
- `infilled_stories.csv` â†’ Infills generated using `infill_generator_using_gpt4.py`.

### ğŸ”¹ Code
- `python infill_generator_using_gpt4.py` â†’ Run the script to generate infilled stories.
- `python gpt2_model_pred.py` â†’ Run this script to predicts next tokens using GPT-2 and plots graphs.
- `python llama2_model_pred.py` â†’ Run this script to predicts next tokens using LLaMA-2 and plots graphs.

## ğŸ“ŠResults
 
### GPT-2 Model Predictions:
 
- `gpt2_first_order_result.pdf` â†’ First-order question results generated by gpt2.
 
- `gpt2_second_order_result.pdf` â†’ Second-order question results generated by gpt2.
 
- `gpt2_zero_order_result.pdf` â†’ Zero-order question results generated by gpt2.
 
### LLaMA-2 Model Predictions:
 
- `llama2_first_order_result.pdf` â†’ First-order question results generated by llama2.
 
- `llama2_second_order_result.pdf` â†’ Second-order question results generated by llama2.
 
- `llama2_zero_order_result.pdf` â†’ Zero-order question results generated by llama2.
 

---

## ğŸ§° Requirements

- `requirements.txt` â†’ Contains all the necessary dependencies.

Install dependencies using:

```bash
!pip install -r requirements.txt
